{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "categorical-encodings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vijaykriishna/talkingdata_adtracking/blob/master/categorical_encodings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m65_Mr4bZPkN"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Apply more advanced encodings to encode the categorical variables ito improve the classifier model. The encodings implemented are:\n",
        "\n",
        "- Count Encoding\n",
        "- Target Encoding\n",
        "- CatBoost Encoding\n",
        "\n",
        "Refit the classifier after each encoding to check its performance on hold-out data. \n",
        "\n",
        "Begin by running the next code cell to set up the notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9iXKo_iZPkO"
      },
      "source": [
        "The next code cell repeats the work that you did in the previous exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0M0_fp0obx4B",
        "outputId": "416e088e-017f-4b76-9604-306b8ff30b77"
      },
      "source": [
        "!pip install fastparquet"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastparquet\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/b9/844e32d0e3739e5695057dff3a3b9f4abc0fcccff466fdaadb8fedb0ee1d/fastparquet-0.4.1.tar.gz (28.6MB)\n",
            "\u001b[K     |████████████████████████████████| 28.6MB 133kB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.19 in /usr/local/lib/python3.6/dist-packages (from fastparquet) (1.1.4)\n",
            "Requirement already satisfied: numba>=0.28 in /usr/local/lib/python3.6/dist-packages (from fastparquet) (0.48.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from fastparquet) (1.18.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from fastparquet) (20.4)\n",
            "Collecting thrift>=0.11.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/1e/3284d19d7be99305eda145b8aa46b0c33244e4a496ec66440dac19f8274d/thrift-0.13.0.tar.gz (59kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 6.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from fastparquet) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->fastparquet) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19->fastparquet) (2018.9)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from numba>=0.28->fastparquet) (50.3.2)\n",
            "Requirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.6/dist-packages (from numba>=0.28->fastparquet) (0.31.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->fastparquet) (2.4.7)\n",
            "Building wheels for collected packages: fastparquet, thrift\n",
            "  Building wheel for fastparquet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastparquet: filename=fastparquet-0.4.1-cp36-cp36m-linux_x86_64.whl size=7125487 sha256=ed6e36077a7e4544f91bb5ca4a0dabc5932426b5a4d088d8c17892b7dafca467\n",
            "  Stored in directory: /root/.cache/pip/wheels/10/45/cf/492ccb908adde1dd2551bb509a56e4096cce9487167f525120\n",
            "  Building wheel for thrift (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thrift: filename=thrift-0.13.0-cp36-cp36m-linux_x86_64.whl size=345197 sha256=96d38e1674b052b911c73616c831cdfae4cde4d27e977bb54b6d1a814b1b8254\n",
            "  Stored in directory: /root/.cache/pip/wheels/02/a2/46/689ccfcf40155c23edc7cdbd9de488611c8fdf49ff34b1706e\n",
            "Successfully built fastparquet thrift\n",
            "Installing collected packages: thrift, fastparquet\n",
            "Successfully installed fastparquet-0.4.1 thrift-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G88HFSm1cj2-",
        "outputId": "c7680c65-88c5-4ae1-e1f9-b4837cb4a385"
      },
      "source": [
        "pip install category_encoders"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting category_encoders\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/57/fcef41c248701ee62e8325026b90c432adea35555cbc870aff9cfba23727/category_encoders-2.2.2-py2.py3-none-any.whl (80kB)\n",
            "\r\u001b[K     |████                            | 10kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 20kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 30kB 9.9MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 40kB 8.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 51kB 3.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 61kB 4.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 71kB 4.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 3.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.18.5)\n",
            "Requirement already satisfied: pandas>=0.21.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.1.4)\n",
            "Requirement already satisfied: patsy>=0.5.1 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.5.1)\n",
            "Requirement already satisfied: statsmodels>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.10.2)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from category_encoders) (0.22.2.post1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.21.1->category_encoders) (2018.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from patsy>=0.5.1->category_encoders) (1.15.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.20.0->category_encoders) (0.17.0)\n",
            "Installing collected packages: category-encoders\n",
            "Successfully installed category-encoders-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gImqlaydZPkO"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing, metrics\n",
        "import lightgbm as lgb\n",
        "\n",
        "clicks = pd.read_parquet('/content/input/baseline_data.pqt')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CC08GXQZPkO"
      },
      "source": [
        "Next, we define a couple functions that you'll use to test the encodings that you implement in this exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "CgyqKyF-ZPkO"
      },
      "source": [
        "def get_data_splits(dataframe, valid_fraction=0.1):\n",
        "    \"\"\"Splits a dataframe into train, validation, and test sets.\n",
        "\n",
        "    First, orders by the column 'click_time'. Set the size of the \n",
        "    validation and test sets with the valid_fraction keyword argument.\n",
        "    \"\"\"\n",
        "\n",
        "    dataframe = dataframe.sort_values('click_time')\n",
        "    valid_rows = int(len(dataframe) * valid_fraction)\n",
        "    train = dataframe[:-valid_rows * 2]\n",
        "    # valid size == test size, last two sections of the data\n",
        "    valid = dataframe[-valid_rows * 2:-valid_rows]\n",
        "    test = dataframe[-valid_rows:]\n",
        "    \n",
        "    return train, valid, test\n",
        "\n",
        "def train_model(train, valid, test=None, feature_cols=None):\n",
        "    if feature_cols is None:\n",
        "        feature_cols = train.columns.drop(['click_time', 'attributed_time',\n",
        "                                           'is_attributed'])\n",
        "    dtrain = lgb.Dataset(train[feature_cols], label=train['is_attributed'])\n",
        "    dvalid = lgb.Dataset(valid[feature_cols], label=valid['is_attributed'])\n",
        "    \n",
        "    param = {'num_leaves': 64, 'objective': 'binary', \n",
        "             'metric': 'auc', 'seed': 7}\n",
        "    num_round = 1000\n",
        "    bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], \n",
        "                    early_stopping_rounds=20, verbose_eval=False)\n",
        "    \n",
        "    valid_pred = bst.predict(valid[feature_cols])\n",
        "    valid_score = metrics.roc_auc_score(valid['is_attributed'], valid_pred)\n",
        "    print(f\"Validation AUC score: {valid_score}\")\n",
        "    \n",
        "    if test is not None: \n",
        "        test_pred = bst.predict(test[feature_cols])\n",
        "        test_score = metrics.roc_auc_score(test['is_attributed'], test_pred)\n",
        "        return bst, valid_score, test_score\n",
        "    else:\n",
        "        return bst, valid_score"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVfl4NifZPkO"
      },
      "source": [
        "Run this cell to get a baseline score. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsq66IVqZPkO",
        "outputId": "600740ce-cba4-4101-b367-d128c5f083d2"
      },
      "source": [
        "print(\"Baseline model\")\n",
        "train, valid, test = get_data_splits(clicks)\n",
        "baseline_score = train_model(train, valid)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline model\n",
            "Validation AUC score: 0.9622743228943659\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEUHf2IvZPkO"
      },
      "source": [
        "### 1) Categorical encodings and leakage\n",
        "\n",
        "These encodings are all based on statistics calculated from the dataset like counts and means. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_cegfTzZPkP"
      },
      "source": [
        "### 2) Count encodings\n",
        "\n",
        "Begin by running the next code cell to get started."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SNzLcC4aZPkP",
        "outputId": "b74054a6-7a8a-4232-a854-23eca7241e92"
      },
      "source": [
        "import category_encoders as ce\n",
        "\n",
        "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
        "train, valid, test = get_data_splits(clicks)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbt3mtZHZPkP"
      },
      "source": [
        "Next, encode the categorical features `['ip', 'app', 'device', 'os', 'channel']` using the count of each value in the data set. \n",
        "- Using `CountEncoder` from the `category_encoders` library, fit the encoding using the categorical feature columns defined in `cat_features`. \n",
        "- Then apply the encodings to the train and validation sets, adding them as new columns with names suffixed `\"_count\"`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSjQ18BhZPkP",
        "outputId": "41ef47cb-1ff6-4a04-c58f-554a32f8bf93"
      },
      "source": [
        "# Create the count encoder\n",
        "count_enc = ce.CountEncoder(cols=cat_features)\n",
        "\n",
        "# Learn encoding from the training set\n",
        "count_enc.fit(train[cat_features])\n",
        "\n",
        "# Apply encoding to the train and validation sets as new columns\n",
        "# Make sure to add `_count` as a suffix to the new columns\n",
        "train_encoded = train.join(count_enc.transform(train[cat_features]).add_suffix('_count'))\n",
        "valid_encoded = valid.join(count_enc.transform(valid[cat_features]).add_suffix('_count'))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zf-mLDPFZPkP"
      },
      "source": [
        "Run the next code cell to see how count encoding changes the results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCU_WafzZPkP",
        "outputId": "9b787c2d-b92c-41ce-b4ec-70385a168a6e"
      },
      "source": [
        "# Train the model on the encoded datasets\n",
        "# This can take around 30 seconds to complete\n",
        "count_enc_score = train_model(train_encoded, valid_encoded)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation AUC score: 0.9653051135205329\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AebkZ_3yZPkP"
      },
      "source": [
        "Count encoding improved our model's score!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLaYPHpdZPkP"
      },
      "source": [
        "### 3) Why is count encoding effective?\n",
        "At first glance, it could be surprising that count encoding helps make accurate models. \n",
        "Why do you think is count encoding is a good idea, or how does it improve the model score?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-55ZvidrZPkP"
      },
      "source": [
        "### 4) Target encoding\n",
        "\n",
        "Here you'll try some supervised encodings that use the labels (the targets) to transform categorical features. The first one is target encoding. \n",
        "- Create the target encoder from the `category_encoders` library. \n",
        "- Then, learn the encodings from the training dataset, apply the encodings to all the datasets, and retrain the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JyLxn_S1ZPkP",
        "outputId": "8009bdc9-b653-4d8f-96d7-8a1b8cc5f32a"
      },
      "source": [
        "# Create the target encoder. You can find this easily by using tab completion.\n",
        "# Start typing ce. the press Tab to bring up a list of classes and functions.\n",
        "target_enc = ce.TargetEncoder(cols=cat_features)\n",
        "\n",
        "# Learn encoding from the training set. Use the 'is_attributed' column as the target.\n",
        "target_enc.fit(train[cat_features], train['is_attributed'])\n",
        "\n",
        "# Apply encoding to the train and validation sets as new columns\n",
        "# Make sure to add `_target` as a suffix to the new columns\n",
        "train_encoded = train.join(target_enc.transform(train[cat_features]).add_suffix('_target'))\n",
        "valid_encoded = valid.join(target_enc.transform(valid[cat_features]).add_suffix('_target'))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAFGkGD-ZPkP"
      },
      "source": [
        "Run the next cell to see how target encoding affects your results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fToBAkKYZPkP",
        "outputId": "e90963b1-825b-4a7a-ea25-18ddcce3c6a6"
      },
      "source": [
        "target_enc_score = train_model(train_encoded, valid_encoded)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation AUC score: 0.9540530347873288\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHWPF3J1ZPkQ"
      },
      "source": [
        "### 5) Try removing IP encoding\n",
        "\n",
        "If you leave `ip` out of the encoded features and retrain the model with target encoding, you should find that the score increases and is above the baseline score! Why do you think the score is below baseline when we encode the IP address but above baseline when we don't?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsMJtK-XZPkQ"
      },
      "source": [
        "### 6) CatBoost Encoding\n",
        "\n",
        "The CatBoost encoder is supposed to work well with the LightGBM model. Encode the categorical features with `CatBoostEncoder` and train the model on the encoded data again."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ur13zDsZPkQ",
        "outputId": "c9f9d50f-e1eb-4e4c-8036-1f1fdb693853"
      },
      "source": [
        "# Remove IP from the encoded features\n",
        "cat_features = ['app', 'device', 'os', 'channel']\n",
        "\n",
        "# Create the CatBoost encoder\n",
        "cb_enc = ce.CatBoostEncoder(cols=cat_features, random_state=7)\n",
        "\n",
        "# Learn encoding from the training set\n",
        "cb_enc.fit(train[cat_features], train['is_attributed'])\n",
        "\n",
        "# Apply encoding to the train and validation sets as new columns\n",
        "# Make sure to add `_cb` as a suffix to the new columns\n",
        "train_encoded = train.join(cb_enc.transform(train[cat_features]).add_suffix('_cb'))\n",
        "valid_encoded = valid.join(cb_enc.transform(valid[cat_features]).add_suffix('_cb'))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frFth4MRZPkQ"
      },
      "source": [
        "Run the next code cell to see how the CatBoost encoder changes your results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIEZ3wSSZPkQ",
        "outputId": "7d914154-012b-4a5b-beeb-6d6f3112304c"
      },
      "source": [
        "catboost_enc_score = train_model(train_encoded, valid_encoded)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation AUC score: 0.962868024575231\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}