{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "feature-generation.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vijaykriishna/talkingdata_adtracking/blob/master/feature_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TpbLqNvuqFeY"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "Create new features from the existing data. Compare the score lift for each new feature compared to a baseline model. First off, run the cells below to set up a baseline dataset and model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXhLhB1RqFeY",
        "outputId": "93da19a0-645b-4065-e290-ade6126943aa"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn import preprocessing, metrics\n",
        "import lightgbm as lgb\n",
        "\n",
        "# Create features from   timestamps\n",
        "click_data = pd.read_csv('/content/input/train_sample.csv', \n",
        "                         parse_dates=['click_time'])\n",
        "click_times = click_data['click_time']\n",
        "clicks = click_data.assign(day=click_times.dt.day.astype('uint8'),\n",
        "                           hour=click_times.dt.hour.astype('uint8'),\n",
        "                           minute=click_times.dt.minute.astype('uint8'),\n",
        "                           second=click_times.dt.second.astype('uint8'))\n",
        "\n",
        "# Label encoding for categorical features\n",
        "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
        "for feature in cat_features:\n",
        "    label_encoder = preprocessing.LabelEncoder()\n",
        "    clicks[feature] = label_encoder.fit_transform(clicks[feature])\n",
        "    \n",
        "def get_data_splits(dataframe, valid_fraction=0.1):\n",
        "\n",
        "    dataframe = dataframe.sort_values('click_time')\n",
        "    valid_rows = int(len(dataframe) * valid_fraction)\n",
        "    train = dataframe[:-valid_rows * 2]\n",
        "    # valid size == test size, last two sections of the data\n",
        "    valid = dataframe[-valid_rows * 2:-valid_rows]\n",
        "    test = dataframe[-valid_rows:]\n",
        "    \n",
        "    return train, valid, test\n",
        "\n",
        "def train_model(train, valid, test=None, feature_cols=None):\n",
        "    if feature_cols is None:\n",
        "        feature_cols = train.columns.drop(['click_time', 'attributed_time',\n",
        "                                           'is_attributed'])\n",
        "    dtrain = lgb.Dataset(train[feature_cols], label=train['is_attributed'])\n",
        "    dvalid = lgb.Dataset(valid[feature_cols], label=valid['is_attributed'])\n",
        "    \n",
        "    param = {'num_leaves': 64, 'objective': 'binary', \n",
        "             'metric': 'auc', 'seed': 7}\n",
        "    num_round = 1000\n",
        "    print(\"Training model. Hold on a minute to see the validation score\")\n",
        "    bst = lgb.train(param, dtrain, num_round, valid_sets=[dvalid], \n",
        "                    early_stopping_rounds=20, verbose_eval=False)\n",
        "    \n",
        "    valid_pred = bst.predict(valid[feature_cols])\n",
        "    valid_score = metrics.roc_auc_score(valid['is_attributed'], valid_pred)\n",
        "    print(f\"Validation AUC score: {valid_score}\")\n",
        "    \n",
        "    if test is not None: \n",
        "        test_pred = bst.predict(test[feature_cols])\n",
        "        test_score = metrics.roc_auc_score(test['is_attributed'], test_pred)\n",
        "        return bst, valid_score, test_score\n",
        "    else:\n",
        "        return bst, valid_score\n",
        "\n",
        "print(\"Baseline model score\")\n",
        "train, valid, test = get_data_splits(clicks)\n",
        "_ = train_model(train, valid)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Baseline model score\n",
            "Training model. Hold on a minute to see the validation score\n",
            "Validation AUC score: 0.9622743228943659\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sN8RSXu8qFeZ"
      },
      "source": [
        "### 1) Add interaction features\n",
        "\n",
        "Add interaction features for each pair of categorical features (ip, app, device, os, channel). As you add the new columns to the dataset, be sure to label encode the values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DtwCWKUVqFeZ"
      },
      "source": [
        "import itertools\n",
        "\n",
        "cat_features = ['ip', 'app', 'device', 'os', 'channel']\n",
        "interactions = pd.DataFrame(index=clicks.index)\n",
        "\n",
        "# Iterate through each pair of features, combine them into interaction features\n",
        "for col1, col2 in itertools.combinations(cat_features, 2):\n",
        "        new_col_name = '_'.join([col1, col2])\n",
        "\n",
        "        # Convert to strings and combine\n",
        "        new_values = clicks[col1].map(str) + \"_\" + clicks[col2].map(str)\n",
        "\n",
        "        encoder = preprocessing.LabelEncoder()\n",
        "        interactions[new_col_name] = encoder.fit_transform(new_values)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koeV9uFtqFea",
        "outputId": "9452d4b5-78a0-4e08-8d77-5f88fdbe36da"
      },
      "source": [
        "clicks = clicks.join(interactions)\n",
        "print(\"Score with interactions\")\n",
        "train, valid, test = get_data_splits(clicks)\n",
        "_ = train_model(train, valid)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score with interactions\n",
            "Training model. Hold on a minute to see the validation score\n",
            "Validation AUC score: 0.9626212895350978\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "721mULGWqFea"
      },
      "source": [
        "# Generating numerical features\n",
        "\n",
        "Adding interactions is a quick way to create more categorical features from the data. It's also effective to create new numerical features, you'll typically get a lot of improvement in the model. This takes a bit of brainstorming and experimentation to find features that work well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLNNyM0aqFea"
      },
      "source": [
        "### 2) Number of events in the past six hours\n",
        "\n",
        "The first feature you'll be creating is the number of events from the same IP in the last six hours. It's likely that someone who is visiting often will download the app.\n",
        "\n",
        "Implement a function `count_past_events` that takes a Series of click times (timestamps) and returns another Series with the number of events in the last six hours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JagoMWUcqFea"
      },
      "source": [
        "def count_past_events(series):\n",
        "    series = pd.Series(series.index, index=series)\n",
        "    # Subtract 1 so the current event isn't counted\n",
        "    past_events = series.rolling('6h').count() - 1\n",
        "    return past_events"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAV97CKeqFea"
      },
      "source": [
        "Because this can take a while to calculate on the full data, we'll load pre-calculated versions in the cell below to test model performance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WevkHQlqFea",
        "outputId": "b7e50324-a9c2-40fb-d576-982eafb5e522"
      },
      "source": [
        "# Loading in from saved Parquet file\n",
        "past_events = pd.read_parquet('/content/input/past_6hr_events.pqt')\n",
        "clicks['ip_past_6hr_counts'] = past_events\n",
        "\n",
        "train, valid, test = get_data_splits(clicks)\n",
        "_ = train_model(train, valid)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model. Hold on a minute to see the validation score\n",
            "Validation AUC score: 0.9647255487084245\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ug_wpDTRqFea"
      },
      "source": [
        "### 3) Features from future information\n",
        "\n",
        "In the last exercise you created a feature that looked at past events. You could also make features that use information from events in the future. Should you use future events or not? \n",
        "\n",
        "Run the following line after you've decided your answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vgl07tLqFea"
      },
      "source": [
        "### 4) Time since last event\n",
        "\n",
        "Implement a function `time_diff` that calculates the time since the last event in seconds from a Series of timestamps. This will be ran like so:\n",
        "\n",
        "```python\n",
        "timedeltas = clicks.groupby('ip')['click_time'].transform(time_diff)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uOvci5yGqFea"
      },
      "source": [
        "def time_diff(series):\n",
        "    \"\"\"Returns a series with the time since the last timestamp in seconds.\"\"\"\n",
        "    return series.diff().dt.total_seconds()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNsR5pj2qFeb"
      },
      "source": [
        "We'll again load pre-computed versions of the data, which match what your function would return"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovJxfDPJqFeb",
        "outputId": "e57a071f-9822-45cc-e648-8ba16bb3a3b7"
      },
      "source": [
        "# Loading in from saved Parquet file\n",
        "past_events = pd.read_parquet('/content/input/time_deltas.pqt')\n",
        "clicks['past_events_6hr'] = past_events\n",
        "\n",
        "train, valid, test = get_data_splits(clicks.join(past_events))\n",
        "_ = train_model(train, valid)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training model. Hold on a minute to see the validation score\n",
            "Validation AUC score: 0.9651116624672765\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADlqmDwNqFeb"
      },
      "source": [
        "### 5) Number of previous app downloads\n",
        "\n",
        "It's likely that if a visitor downloaded an app previously, it'll affect the likelihood they'll download one again. Implement a function `previous_attributions` that returns a Series with the number of times an app has been downloaded (`'is_attributed' == 1`) before the current event."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "HUW4BUy_qFeb"
      },
      "source": [
        "def previous_attributions(series):\n",
        "    \"\"\"Returns a series with the number of times an app has been downloaded.\"\"\"\n",
        "    sums = series.expanding(min_periods=2).sum() - series\n",
        "    return sums"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QtKfUIg3qFeb"
      },
      "source": [
        "Again loading pre-computed data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "y7t4XA8cqFeb"
      },
      "source": [
        "# Loading in from saved Parquet file\n",
        "past_events = pd.read_parquet('/content/input/downloads.pqt')\n",
        "clicks['ip_past_6hr_counts'] = past_events\n",
        "\n",
        "train, valid, test = get_data_splits(clicks)\n",
        "_ = train_model(train, valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VY3e_hK-qFeb"
      },
      "source": [
        "### 6) Tree-based vs Neural Network Models\n",
        "\n",
        "So far we've been using LightGBM, a tree-based model. Would these features we've generated work well for neural networks as well as tree-based models?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhQYChRSqFeb"
      },
      "source": [
        "Now that you've generated a bunch of different features, you'll typically want to remove some of them to reduce the size of the model and potentially improve the performance. Next, how to do feature selection using a few different methods such as L1 regression and Boruta."
      ]
    }
  ]
}